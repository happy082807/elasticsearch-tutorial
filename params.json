{"name":"Elasticsearch-tutorial","tagline":"Examples of pyes ( elasticsearch python library ) and documents","body":"# pyes API\r\n\r\n- [Simple Example](#Simple_Example)\r\n\t- [Create Connection](#Creat_Connection)\r\n\t- [Index Data](#Index_Data)\r\n\t\t- [Sample Dataset](#Sample_Dataset)\r\n\t- [Create Simple Query](#Creat_Simple_Query)\r\n\t- [Create Simple Aggregation](#Creat_Simple_Aggregation)\r\n\t- [Get Results](#Get_Results)\r\n\t\r\n- [Connection](#Connection)\r\n\t- [Simple Connection](#Simple_Connection)\r\n\t- [Connection With Basic Auth](#Connection_With_Basic_Auth)\r\n\t\r\n- [Query](#Query)\r\n\t- [Match All Query](#Match_All_Query)\r\n\t- [Term Query](#Term_Query)\r\n\t- [Range Query](#Range_Query)\r\n\t- [Boolean Query](#Boolean_Query)\r\n\t\r\n- [Filter](#Filter)\r\n\t- [Terms Filter](#Terms_Filter)\r\n\t- [Terms Filter with Terms Lookup](#Terms_Filter_with_Terms_Lookup)\r\n\t- [Boolean Filter](#Boolean_Filter)\r\n\t\r\n- [Aggreation](#Aggreation)\r\n\t- [Term Aggregation](#Term_Aggregation)\r\n\t- [Date Histogram Aggregation](#Date_Histogram_Aggregation)\r\n\t- [Statistic Aggregation](#Statistic_Aggregation)\r\n\t\r\n- [Format Translator](#Format_Translator)\r\n\t- [ES aggs 2 layers to Matrix](#ES_aggs_2_layers_to_double[][]_Matrix)\r\n\t\r\n- [Files tools](#Files_tools)\r\n\t- [ES aggs 1 layer to CSV](#ES_aggs_1_layer_to_CSV)\r\n\t- [Matrix to CSV](#Double[][]_Matrix_to_CSV)\r\n\r\n\r\n\r\n\r\n##<a id=\"Simple_Example\"></a>Simple Example\r\n以下內容是一個簡單的範例，看完以下內容後在針對每一個小塊，去看後面張傑更詳細的介紹或是變化．每一個區塊都可以獨立帶換掉，組成不同的效果．在執行下列程式碼之前，記得先 import 以下 libraries．\r\n\t\r\n\timport json\r\n\tfrom pyes import ES,MatchAllQuery\r\n\tfrom pyes.aggs import TermsAgg\r\n\t# 以下兩個 tool 是自己寫的 ＸＤ\r\n\tfrom tools.FileTools import FileTools\r\n\tfrom tools.FormatTranslator import FormatTranslator\r\n\t\r\n###<a id=\"Creat_Connection\"></a>Create Connection\r\nconnection 顧名思義是用來與 ES 建立連線．之後所有的 index ( 新增 ) 與 Query ( 查詢 ) 都會使用 connection 物件．\r\n\t# 最簡單的connection就是連接 localhost:9200 ，但是因為預設就是這些值，所以可以不用打\r\n\tconn = ES()\r\n###<a id=\"Index_Data\"></a>Index Data\r\n以下是簡單的新增資料的做法，讀入資料為 JSON 格式．放入 index 指令中．第二欄位是要新增的 index 名稱，再來是 type 然後 id ．\r\n\r\n\tdataset_json = open(\"../dataset.json\")\r\n\tdataset = json.load(dataset_json)['data']\r\n\tfor data in dataset:\r\n    \tconn.index(data, \"example_index\", \"example_type\", \"example_id_\"+str(dataset.index(data)))\r\n\r\n####<a id=\"Sample_Dataset\"></a>Sample Dataset\r\n以下是範例的 dataset ，另存成 dataset.json 給上面的 code 吃\r\n\r\n    {\r\n      \"data\": [\r\n        {\r\n          \"date\": \"2014-09-13\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"Elasticsearch means full text search has never been so easy\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-14\",\r\n          \"name\": \"John Smith\",\r\n          \"tweet\": \"@mary it is not just text, it does everything\",\r\n          \"user_id\": 1\r\n        },\r\n        {\r\n          \"date\": \"2014-09-15\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"However did I manage before Elasticsearch?\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-16\",\r\n          \"name\": \"John Smith\",\r\n          \"tweet\": \"The Elasticsearch API is really easy to use\",\r\n          \"user_id\": 1\r\n        },\r\n        {\r\n          \"date\": \"2014-09-17\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"The Query DSL is really powerful and flexible\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-18\",\r\n          \"name\": \"John Smith\",\r\n          \"user_id\": 1\r\n        },\r\n        {\r\n          \"date\": \"2014-09-19\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"Geo-location aggregations are really cool\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-20\",\r\n          \"name\": \"John Smith\",\r\n          \"tweet\": \"Elasticsearch surely is one of the hottest new NoSQL products\",\r\n          \"user_id\": 1\r\n        },\r\n        {\r\n          \"date\": \"2014-09-21\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"Elasticsearch is built for the cloud, easy to scale\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-22\",\r\n          \"name\": \"John Smith\",\r\n          \"tweet\": \"Elasticsearch and I have left the honeymoon stage, and I still love her.\",\r\n          \"user_id\": 1\r\n        },\r\n        {\r\n          \"date\": \"2014-09-23\",\r\n          \"name\": \"Mary Jones\",\r\n          \"tweet\": \"So yes, I am an Elasticsearch fanboy\",\r\n          \"user_id\": 2\r\n        },\r\n        {\r\n          \"date\": \"2014-09-24\",\r\n          \"name\": \"John Smith\",\r\n          \"tweet\": \"How many more cheesy tweets do I have to write?\",\r\n          \"user_id\": 1\r\n        }\r\n      ]\r\n    }\r\n\r\n###<a id=\"Creat_Simple_Query\"></a>Create Simple Query\r\nQuery 是一次查詢中必要的角色，在這邊使用 Match All 就是全拿\r\n\r\n\tquery = MatchAllQuery()\r\n###<a id=\"Creat_Simple_Aggregation\"></a>Create Simple Aggregation\r\nAggregation 是用來 summarize 資訊的方法，在這邊使用的是相同 term 的個數統計． sub_aggs是留給如果要在進一步作第二層 aggregation 時使用的， size 則是要顯示 aggregation 後的前幾名 ( 100 就是前 100 名 )\r\n\r\n\tagg = TermsAgg('agg1', field=\"name\",sub_aggs=[],size=100)\r\n\r\n###<a id=\"Get_Results\"></a>Get Results\r\n在pyes中取得搜尋內容的方式如下，要注意的是在預設的情況下 pyes 是不希望使用者一口氣拉回所有資料，所以要採用一筆一筆的方式拿出來．使用 Search 物件將 query 以及 agg 兩個部分包在一起．Search 物件所定義的 size 是表示Query 出來筆數限制．\r\n\t\r\n\t# 加入 query 以及 aggs 資訊進入 Search 中，並且可以用 .serialize() 印出現階段語法，檢視當前的語法是否正確\r\n\tsearch = Search(query,size=5)\r\n\tsearch.agg.add(agg)\r\n\tprint search.serialize()\r\n\t\r\n\t# 創造出 ResultSet 物件\r\n\t# 注意！！！！在現階段並沒有真正去做進 ES 查詢的動作\r\n\t# 要在之後要讀取 result 的內容時才會真正去查詢\r\n\tresult = conn.search(search, \"example_index\", \"example_type\" )\r\n\t\r\n\t# 依序印出每一筆查詢結果，以及印出 aggregation 的結果\r\n\t# 使用 json.dumps(XXXXXXX,indent=2) 只是為了好閱讀\r\n\t# 這邊使用 search.size 而不是使用 len(result) 是因為後者永遠是表示總共搜尋到幾篇文章\r\n\t# 前者是表示要顯示幾筆結果。當已經限制顯示數量時，就不能用 .next() 走到限制筆數之外！\r\n\t# 當然也可以直接用 for XXX in result: 的寫法確保不要走超過！\r\n\t# 這邊 aggregation 的結果會發現名字會被拆開，是因為我們是對 term 做，而 ES 本身會做段詞，所以名字都會被拆成個別的 terms\r\n\tfor i in range(0,search.size):\r\n    \tprint json.dumps(result.next(),indent=2)\r\n\tprint json.dumps(result.aggs,indent=2)\r\n\r\n\t# 若是硬要一口氣取得所有結果自己做 parse 可偷偷呼叫下列隱藏 function 以及隱藏屬性\r\n\tresult._do_search()\r\n\tprint json.dumps(result._results,indent=2)\r\n\t\r\n\t\r\n\r\n##<a id=\"Connection\"></a>Connection\r\n\r\n###<a id=\"Simple_Connection\"></a>Simple Connection\r\n\r\n\t#一開始要先\r\n\timport pyes\r\n\t#以下會列出所有的路徑，所以這份文件看不到 \"from pyes import *\"\r\n\tconn=pyes.es.ES('localhost:9200') #domain:port\r\n\r\n###<a id=\"Connection_With_Basic_Auth\"></a>Connection With Basic Auth\r\n\t\r\n\tconn=pyes.es.ES('http://localhost:9200' ,basic_auth={'username':'username','password':'password'},timeout=100, max_retries=30, bulk_size=2,default_indices='facebook',default_types='opinion' )\r\n\r\n##<a id=\"Query\"></a>Query\r\n\r\n###<a id=\"Match_All_Query\"></a>Match All Query\r\n\timport pyes\r\n\t\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tq = pyes.query.MatchAllQuery()\r\n\t\r\n\tresult = conn.search(query=q , indices='example_index' , doc_types='example_type') \r\n\t# indice與doc_types可以使用多重選擇，但記得要用[]包起來。\r\n\t\r\n\tfor i in result:\r\n\t\tprint i\r\n\t# 用迴圈可以把結果印出來。\r\n\r\n###<a id=\"Term_Query\"></a>Term Query\r\n\timport pyes\r\n\t\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\t\r\n\t# 在這邊要特別注意， dataset 中的人物叫 \"J\"ohn 但是查詢的時候要打 \"j\"hon\r\n\t# ES 不分大小寫，但是查詢只能用小寫！！\r\n\ttq = pyes.query.TermQuery(field=\"name\", value=\"john\")\r\n\t\r\n\tresult = conn.search(query=tq, indices='example_index' , doc_types='example_type')\r\n\tfor i in result:\r\n\t\tprint i\r\n\r\n###<a id=\"Range_Query\"></a>Range Query\r\n\timport pyes\r\n\t\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tESR = pyes.ESRange(field=\"date\", from_value=\"2014-09-15\", to_value=\"2014-09-18\", include_lower=True ,include_upper=False)\r\n\t# 因為 include_upper 是 False 所以 upper bound 並不會被包含 ( 結果不會有 2014-09-18 )\r\n    \r\n    rq = pyes.query.RangeQuery(qrange=ESR)\r\n    \r\n    result = conn.search(query=rq, indices='example_index' , doc_types='example_type')\r\n    for i in result:\r\n\t\tprint i\r\n    \r\n\r\n###<a id=\"Boolean_Query\"></a>Boolean Query\r\n\timport pyes\r\n\t\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tbq = pyes.query.BoolQuery() \r\n\t# BoolQuery本身是一個Query的組合，可以使用add_must(), add_must_not(), add_should()來使用。\r\n\t\r\n\tbq.add_must(pyes.query.TermQuery(\"tweet\",\"elasticsearch\")) #(field, term)\r\n\tbq.add_must_not(pyes.query.TermQuery(\"name\",\"john\")) #(field, term)\r\n\t# tweet 包含 elasticsearch 但是作者不是 John ( 注意大小寫！！ )\r\n\t\r\n\tresult = conn.search(query=bq, indices='example_index' , doc_types='example_type') \r\n\t#使用Boolquery來當query的值。\r\n\t\r\n\tfor i in result:\r\n\t\tprint i\r\n\r\n##<a id=\"Filter\"></a>Filter\r\n\r\n###<a id=\"Terms_Filter\"></a>Terms Filter\r\n\t# 有兩種方式來query,分別為TermFilter與TermsFilter。兩者的差別為一個term與多個term的query。所以其實可以都用TermsFilter。\r\n\timport pyes\r\n\t \r\n\tconn = pyes.es.ES('localhost:9200')\r\n\ttf  = pyes.filters.TermFilter(field=\"tweet\", value=\"elasticsearch\")\r\n\ttsf = pyes.filters.TermsFilter(field=\"tweet\", values=[\"elasticsearch\",\"easy\"]) \r\n\t# values後面等於的東西一定要加[]\r\n\t\r\n\tfq=pyes.query.FilteredQuery(pyes.query.MatchAllQuery(), tsf) \r\n\t# 要把filter拿去做query必須要以FilteredQuery來query。\r\n\t\r\n\tresult = conn.search(query= fq, indices=\"example_index\" , doc_types=\"example_type\")\r\n\tfor i in result:\r\n\t\tprint i\r\n\t\r\n\t# 由輸出結果可知 filter 多個值得時候，他們是採用 or 而不是 and 因此只要出現其中一個 term 就算有比對成功。\r\n\t\r\n###<a id=\"#Terms_Filter_with_Terms_Lookup\"></a>Terms Filter with Terms Lookup\r\n\r\n\timport pyes\r\n\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tconn.index({\"list\":[\"elasticsearch\",\"easy\"]}, \"example_index\", \"example_type\", \"terms_list\")\r\n\r\n\t# 使用 Terms Lookup 載入 List\r\n\ttl = pyes.TermsLookup(index=\"example_index\", type=\"example_type\", id=\"terms_list\", path='list')\r\n\ttsf = pyes.filters.TermsFilter(\"tweet\",tl)\r\n\tfq=pyes.query.FilteredQuery(pyes.query.MatchAllQuery(), tsf) \r\n\t\r\n\tresult = conn.search(query= fq, indices=\"example_index\" , doc_types=\"example_type\")\r\n\tfor i in result:\r\n\t    print i\r\n\t\r\n###<a id=\"Boolean_Filter\"></a>Boolean Filter\r\n\t#BoolFilter本身是一個Query的組合，可以使用add_must(), add_must_not(), add_should()來使用。\r\n\timport pyes\r\n\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tbf = pyes.filters.BoolFilter()\r\n\tbf.add_must(pyes.filters.TermFilter(\"tweet\",\"elasticsearch\"))\r\n\tbf.add_must(pyes.filters.TermFilter(\"tweet\",\"easy\"))\r\n\tfq=pyes.query.FilteredQuery(pyes.query.MatchAllQuery(), bf)\r\n\r\n\tresult = conn.search(query= fq, indices=\"example_index\" , doc_types=\"example_type\")\r\n\tfor i in result:\r\n    \tprint i\r\n\r\n\r\n##<a id=\"Aggreation\"></a>Aggreation\r\n\r\n###<a id=\"Term_Aggregation\"></a>Term Aggregation\r\n\r\n\timport pyes\r\n\timport json\r\n\t# 單層集合（做兩個不同aggregation）\r\n\tconn = pyes.es.ES('localhost:9200')\r\n\tq = pyes.query.MatchAllQuery()\r\n\ttagg = pyes.aggs.TermsAgg('name', field= 'name') \r\n\ttagg1 = pyes.aggs.TermsAgg('user_id', field= 'user_id')\r\n\t# 需要給一個名字給出來集合。\r\n\r\n\tqsearch = pyes.query.Search(q) \r\n\t# 要做aggregation需要使用Search,因為他裡面有一個.agg。\r\n\t# 不管是如何一定要有query的方式，此以MatchAllQuery()作為query方式。\r\n\t# This \"Search\" is under pyes.query, http://pydoc.net/Python/pyes/0.99.5/pyes.query\r\n\r\n\tqsearch.agg.add(tagg) \r\n\tqsearch.agg.add(tagg1)\r\n\t# 將aggregation的方法加入到qsearch.agg裡面\r\n\t\r\n\trs = conn.search(query=qsearch,index='example_index',type=\"example_type\") \r\n\tprint json.dumps(rs.aggs,indent=2) \r\n\t# 我們要的結果\r\n\t\r\n\t===========================================================================================\r\n\t\r\n\t# 雙層集合(階層集合)（注意sub_aggs，重點）\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\ttagg = pyes.aggs.TermsAgg('user_id', field= 'user_id', sub_aggs=[]) \r\n\ttagg1 = pyes.aggs.TermsAgg('name', field= 'name')  \r\n\ttagg.sub_aggs.append(tagg1) \r\n\t# 將tagg1加到tagg.sub_aggs裡面。\r\n\tqsearch = pyes.query.Search(q) \r\n\t# This \"Search\" is under pyes.query, http://pydoc.net/Python/pyes/0.99.5/pyes.query\r\n\tqsearch.agg.add(tagg)\r\n\r\n\trs = conn.search(query=qsearch , indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\r\n\t\r\n###<a id=\"Date_Histogram_Aggregation\"></a>Date Histogram Aggregation\r\n\timport pyes\r\n\timport json\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\tDHAgg = pyes.aggs.DateHistogramAgg('3date' ,field='date', interval='3d') \r\n\t# 給名字、field、與interval。field必須是時間格式的。\r\n\tqsearch = pyes.Search(q)  \r\n\tqsearch.agg.add(DHAgg)\r\n\r\n\trs = conn.search(query=qsearch ,indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\r\n###<a id=\"Statistic_Aggregation\"></a>Statistic Aggregation\r\n\r\n以下統計的範例因為 dataset 中沒有形態是\"數值\"的欄位，所以使用 user_id 來練習。\r\n\r\n\timport pyes\r\n\timport json\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\tSumAgg = pyes.aggs.SumAgg('sum' ,field='user_id') \r\n\tAvgAgg = pyes.aggs.AvgAgg('sum' ,field='user_id') \r\n\tMaxAgg = pyes.aggs.MaxAgg('sum' ,field='user_id') \r\n\tMinAgg = pyes.aggs.MinAgg('sum' ,field='user_id') \r\n\t# 給名字、field、與interval。field必須是時間格式的。\r\n\tqsearch = pyes.Search(q)  \r\n\tqsearch.agg.add(SumAgg)\r\n\r\n\trs = conn.search(query=qsearch ,indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\t# 因為 user 1 跟 2 個發過 6 篇文章 所以加總會是 18\r\n\r\n##<a id=\"Format_Translator\"></a>Format Translator\r\n以下的工具為自行開發的，不是 pyes 中的。如有需要請跟別人索取\r\n\r\n###<a id=\"ES_aggs_2_layers_to_double[][]_Matrix\"></a>ES aggs 2 layers to Matrix\r\n\r\n\timport pyes\r\n\timport json\r\n\timport FormatTranslator\r\n\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\ttagg = pyes.aggs.TermsAgg('user_id', field= 'user_id', sub_aggs=[]) \r\n\ttagg1 = pyes.aggs.TermsAgg('name', field= 'name')  \r\n\ttagg.sub_aggs.append(tagg1) \r\n\tqsearch = pyes.query.Search(q) \r\n\tqsearch.agg.add(tagg)\r\n\r\n\trs = conn.search(query=qsearch , indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\r\n\t# 使用工具將兩層 aggs 的結果轉換成矩陣表示（ 包含 row index , col index , matrix 三個部分）\r\n\t# 在轉換時要告知 aggs 所使用的名稱 ( 不是 fields 是\"名字\" )\r\n\tformatTranslator = FormatTranslator.FormatTranslator()\r\n\tresult = formatTranslator.ES_Aggs_2_Layer_to_Matrix_and_indice(rs.aggs, agg1_name=\"user_id\", agg2_name=\"name\")\r\n\r\n\tprint result['rowIndexList']\r\n\tprint result['colIndexList']\r\n\tprint result['matrix']\r\n\r\n\r\n##<a id=\"Files_tools\"></a>Files tools\r\n\r\n###<a id=\"ES_aggs_1_layer_to_CSV\"></a>ES aggs 1 layer to CSV\r\n\r\n\timport pyes\r\n\timport json\r\n\timport FormatTranslator\r\n\timport FileTools\r\n\t\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\ttagg = pyes.aggs.TermsAgg('name', field= 'name', sub_aggs=[]) \r\n\tqsearch = pyes.query.Search(q) \r\n\tqsearch.agg.add(tagg)\r\n\r\n\trs = conn.search(query=qsearch , indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\r\n\tfileTools = FileTools.FileTools()\r\n\tfileTools.ES_Aggs_1_Layer_to_CSV(rs.aggs, \"agg.csv\", agg_name=\"name\")\r\n###<a id=\"Double[][]_Matrix_to_CSV\"></a>Matrix to CSV\r\n\r\n\timport pyes\r\n\timport json\r\n\timport FormatTranslator\r\n\timport FileTools\r\n\r\n\tconn=pyes.es.ES('localhost:9200')\r\n\tq = pyes.MatchAllQuery()\r\n\ttagg = pyes.aggs.TermsAgg('user_id', field= 'user_id', sub_aggs=[]) \r\n\ttagg1 = pyes.aggs.TermsAgg('name', field= 'name')  \r\n\ttagg.sub_aggs.append(tagg1) \r\n\tqsearch = pyes.query.Search(q) \r\n\tqsearch.agg.add(tagg)\r\n\r\n\trs = conn.search(query=qsearch , indices='example_index' ,type=\"example_type\" )\r\n\tprint json.dumps(rs.aggs,indent=2)\r\n\r\n\tformatTranslator = FormatTranslator.FormatTranslator()\r\n\tresult = formatTranslator.ES_Aggs_2_Layer_to_Matrix_and_indice(rs.aggs, agg1_name=\"user_id\", agg2_name=\"name\")\r\n\t\r\n\t# 使用工具將結果儲存起來\r\n\tfileTools = FileTools.FileTools()\r\n\tfileTools.List_to_CSV(result['colIndexList'], \"col_index.csv\")\r\n\tfileTools.List_to_CSV(result['rowIndexList'], \"row_index.csv\")\r\n\tfileTools.Matrix_to_CSV(result['matrix'], \"matrix.csv\")\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}